{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Microsoft Corporation. All rights reserved.*  \n",
    "*Licensed under the MIT License.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition Using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before You Start\n",
    "\n",
    "The running time shown in this notebook is on a Standard_NC6 Azure Deep Learning Virtual Machine with 1 NVIDIA Tesla K80 GPU. \n",
    "> **Tip**: If you want to run through the notebook quickly, you can set the **`QUICK_RUN`** flag in the cell below to **`True`** to run the notebook on a small subset of the data and a smaller number of epochs. \n",
    "\n",
    "The table below provides some reference running time on different machine configurations.  \n",
    "\n",
    "|QUICK_RUN|Machine Configurations|Running time|\n",
    "|:---------|:----------------------|:------------|\n",
    "|True|4 **CPU**s, 14GB memory| ~ 2 minutes|\n",
    "|False|4 **CPU**s, 14GB memory| ~1.5 hours|\n",
    "|True|1 NVIDIA Tesla K80 GPUs, 12GB GPU memory| ~ 1 minute|\n",
    "|False|1 NVIDIA Tesla K80 GPUs, 12GB GPU memory| ~ 7 minutes |\n",
    "\n",
    "If you run into CUDA out-of-memory error or the jupyter kernel dies constantly, try reducing the `BATCH_SIZE` and `MAX_SEQ_LENGTH`, but note that model performance will be compromised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set QUICK_RUN = True to run the notebook on a small subset of data and a smaller number of epochs.\n",
    "QUICK_RUN = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This notebook demonstrates how to fine tune [pretrained BERT model](https://github.com/huggingface/pytorch-pretrained-BERT) for named entity recognition (NER) task. Utility functions and classes in the NLP Best Practices repo are used to facilitate data preprocessing, model training, model scoring, and model evaluation. \n",
    "\n",
    "[BERT (Bidirectional Transformers for Language Understanding)](https://arxiv.org/pdf/1810.04805.pdf) is a powerful pre-trained lanaguage model that can be used for multiple NLP tasks, including text classification, question answering, named entity recognition, etc. It's able to achieve state of the art performance with only a few epochs of fine tuning on task specific datasets.  \n",
    "The figure below illustrates how BERT can be fine tuned for NER tasks. The input data is a list of tokens representing a sentence. In the training data, each token has an entity label. After fine tuning, the model predicts an entity label for each token in a given testing sentence. \n",
    "\n",
    "<img src=\"https://nlpbp.blob.core.windows.net/images/bert_architecture.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import scrapbook as sb\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "\n",
    "nlp_path = os.path.abspath('../../')\n",
    "if nlp_path not in sys.path:\n",
    "    sys.path.insert(0, nlp_path)\n",
    "\n",
    "from utils_nlp.models.bert.token_classification import BERTTokenClassifier, create_label_map, postprocess_token_labels\n",
    "from utils_nlp.models.bert.common import Language, Tokenizer\n",
    "from utils_nlp.dataset.wikigold import load_train_test_dfs, get_unique_labels\n",
    "from utils_nlp.common.timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_FRACTION = 1\n",
    "TEST_DATA_FRACTION = 1\n",
    "NUM_TRAIN_EPOCHS = 2\n",
    "\n",
    "if QUICK_RUN:\n",
    "    TRAIN_DATA_FRACTION = 0.1\n",
    "    TEST_DATA_FRACTION = 0.1\n",
    "    NUM_TRAIN_EPOCHS = 1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    BATCH_SIZE = 16\n",
    "else:\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "CACHE_DIR=\"./temp\"\n",
    "\n",
    "# set random seeds\n",
    "RANDOM_SEED = 100\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# model configurations\n",
    "LANGUAGE = Language.ENGLISHCASED\n",
    "DO_LOWER_CASE = False\n",
    "MAX_SEQ_LENGTH = 200\n",
    "\n",
    "# optimizer configuration\n",
    "LEARNING_RATE = 3e-5\n",
    "\n",
    "# data configurations\n",
    "TEXT_COL = \"sentence\"\n",
    "LABELS_COL = \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training and testing data\n",
    "The dataset used in this notebook is the [wikigold dataset](https://www.aclweb.org/anthology/W09-3302). The wikigold dataset consists of 145 mannually labelled Wikipedia articles, including 1841 sentences and 40k tokens in total. The dataset can be directly downloaded from [here](https://github.com/juand-r/entity-recognition-datasets/tree/master/data/wikigold). \n",
    "\n",
    "The helper function `load_train_test_dfs` downloads the data file if it doesn't exist in `local_cache_path`. It splits the dataset into training and testing sets according to `test_fraction`. Because this is a relatively small dataset, we set `test_fraction` to 0.5 in order to have enough data for model evaluation. Running this notebook multiple times with different random seeds produces similar results.   \n",
    "\n",
    "The helper function `get_unique_labels` returns the unique entity labels in the dataset. There are 5 unique labels in the   original dataset: 'O' (non-entity), 'I-LOC' (location), 'I-MISC' (miscellaneous), 'I-PER' (person), and 'I-ORG' (organization). \n",
    "\n",
    "The maximum number of words in a sentence is 144, so we set MAX_SEQ_LENGTH to 200 above, because the number of tokens will grow after WordPiece tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read test and train daat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(input_file_path):\n",
    "#     input_file_path = '/home/fractaluser/NER/data/Genia4ERtest/Genia4EReval1.iob2'\n",
    "    nlp = spacy.load('en_core_web_sm') \n",
    "    data = open(input_file_path,'r').read()\n",
    "    data = re.split(r'\\n\\n',data)\n",
    "    data = list(filter(None,data))\n",
    "    new_data = list()\n",
    "    crf_data = pd.DataFrame()\n",
    "    for sentence in data:\n",
    "        if sentence !='':\n",
    "            word_tag_list = list(map(lambda x:re.split(r'\\t',x),re.split(r'\\n',sentence)))\n",
    "            new_data.append(list(zip(*[i for i in word_tag_list if i!=['']])))\n",
    "    sentence_labelled = pd.DataFrame(columns = ['sentence', 'label'])\n",
    "\n",
    "    for i in new_data:\n",
    "        sentence_labelled = sentence_labelled.append({ 'sentence' : list(i[0]), 'label' : list(i[1])}, ignore_index = True) \n",
    "    return sentence_labelled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_data('/home/NER/data/Genia4ERtraining/Genia4ERtask1.txt')\n",
    "test_df = get_data('/home/NER/data/Genia4ERtest/Genia4EReval1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[IL-2, gene, expression, and, NF-kappa, B, act...</td>\n",
       "      <td>[B-DNA, I-DNA, O, O, B-protein, I-protein, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Activation, of, the, CD28, surface, receptor,...</td>\n",
       "      <td>[O, O, O, B-protein, I-protein, I-protein, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In, primary, T, lymphocytes, we, show, that, ...</td>\n",
       "      <td>[O, B-cell_type, I-cell_type, I-cell_type, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Delineation, of, the, CD28, signaling, cascad...</td>\n",
       "      <td>[O, O, O, B-protein, O, O, O, O, O, O, B-prote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Our, data, suggest, that, lipoxygenase, metab...</td>\n",
       "      <td>[O, O, O, O, B-protein, I-protein, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  [IL-2, gene, expression, and, NF-kappa, B, act...   \n",
       "1  [Activation, of, the, CD28, surface, receptor,...   \n",
       "2  [In, primary, T, lymphocytes, we, show, that, ...   \n",
       "3  [Delineation, of, the, CD28, signaling, cascad...   \n",
       "4  [Our, data, suggest, that, lipoxygenase, metab...   \n",
       "\n",
       "                                               label  \n",
       "0  [B-DNA, I-DNA, O, O, B-protein, I-protein, O, ...  \n",
       "1  [O, O, O, B-protein, I-protein, I-protein, O, ...  \n",
       "2  [O, B-cell_type, I-cell_type, I-cell_type, O, ...  \n",
       "3  [O, O, O, B-protein, O, O, O, O, O, O, B-prote...  \n",
       "4  [O, O, O, O, B-protein, I-protein, O, O, O, O,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Number, of, glucocorticoid, receptors, in, ly...</td>\n",
       "      <td>[O, O, B-protein, I-protein, O, B-cell_type, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, study, demonstrated, a, decreased, level...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-protein, I-protein, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In, the, lymphocytes, with, a, high, GR, numb...</td>\n",
       "      <td>[O, O, B-cell_type, O, O, O, B-protein, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On, the, other, hand, ,, a, decreased, GR, nu...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-protein, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[These, data, showed, that, the, sensitivity, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-cell_type, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  [Number, of, glucocorticoid, receptors, in, ly...   \n",
       "1  [The, study, demonstrated, a, decreased, level...   \n",
       "2  [In, the, lymphocytes, with, a, high, GR, numb...   \n",
       "3  [On, the, other, hand, ,, a, decreased, GR, nu...   \n",
       "4  [These, data, showed, that, the, sensitivity, ...   \n",
       "\n",
       "                                               label  \n",
       "0  [O, O, B-protein, I-protein, O, B-cell_type, O...  \n",
       "1  [O, O, O, O, O, O, O, B-protein, I-protein, O,...  \n",
       "2  [O, O, B-cell_type, O, O, O, B-protein, O, O, ...  \n",
       "3  [O, O, O, O, O, O, O, B-protein, O, O, O, O, O...  \n",
       "4  [O, O, O, O, O, O, O, B-cell_type, O, O, O, O,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18546, 2), (3856, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique entity labels: \n",
      "['O', 'B-protein', 'I-protein', 'B-DNA', 'I-DNA', 'B-cell_type', 'I-cell_type', 'B-cell_line', 'I-cell_line', 'B-RNA', 'I-RNA']\n",
      "\n",
      "Sample sentence: \n",
      "['IL-2', 'gene', 'expression', 'and', 'NF-kappa', 'B', 'activation', 'through', 'CD28', 'requires', 'reactive', 'oxygen', 'production', 'by', '5-lipoxygenase', '.']\n",
      "\n",
      "Sample sentence labels: \n",
      "['B-DNA', 'I-DNA', 'O', 'O', 'B-protein', 'I-protein', 'O', 'O', 'B-protein', 'O', 'O', 'O', 'O', 'O', 'B-protein', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df = load_train_test_dfs(local_cache_path=CACHE_DIR, test_fraction=0.5,random_seed=RANDOM_SEED)\n",
    "label_list = ['O', 'B-protein', 'I-protein', 'B-DNA', 'I-DNA', 'B-cell_type',\n",
    "       'I-cell_type', 'B-cell_line', 'I-cell_line', 'B-RNA', 'I-RNA']\n",
    "print('\\nUnique entity labels: \\n{}\\n'.format(label_list))\n",
    "print('Sample sentence: \\n{}\\n'.format(train_df[TEXT_COL][0]))\n",
    "print('Sample sentence labels: \\n{}\\n'.format(train_df[LABELS_COL][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[IL-2, gene, expression, and, NF-kappa, B, act...</td>\n",
       "      <td>[B-DNA, I-DNA, O, O, B-protein, I-protein, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Activation, of, the, CD28, surface, receptor,...</td>\n",
       "      <td>[O, O, O, B-protein, I-protein, I-protein, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In, primary, T, lymphocytes, we, show, that, ...</td>\n",
       "      <td>[O, B-cell_type, I-cell_type, I-cell_type, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Delineation, of, the, CD28, signaling, cascad...</td>\n",
       "      <td>[O, O, O, B-protein, O, O, O, O, O, O, B-prote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Our, data, suggest, that, lipoxygenase, metab...</td>\n",
       "      <td>[O, O, O, O, B-protein, I-protein, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  [IL-2, gene, expression, and, NF-kappa, B, act...   \n",
       "1  [Activation, of, the, CD28, surface, receptor,...   \n",
       "2  [In, primary, T, lymphocytes, we, show, that, ...   \n",
       "3  [Delineation, of, the, CD28, signaling, cascad...   \n",
       "4  [Our, data, suggest, that, lipoxygenase, metab...   \n",
       "\n",
       "                                               label  \n",
       "0  [B-DNA, I-DNA, O, O, B-protein, I-protein, O, ...  \n",
       "1  [O, O, O, B-protein, I-protein, I-protein, O, ...  \n",
       "2  [O, B-cell_type, I-cell_type, I-cell_type, O, ...  \n",
       "3  [O, O, O, B-protein, O, O, O, O, O, O, B-prote...  \n",
       "4  [O, O, O, O, B-protein, I-protein, O, O, O, O,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=TRAIN_DATA_FRACTION).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=TEST_DATA_FRACTION).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    [IL-2R, chains, were, measured, by, flow, cyto...\n",
       "label       [O, O, O, O, O, O, O, O, O, B-protein, O, O, O...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1855, 2), (386, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that the input text are lists of words instead of raw sentences. This format ensures matching between input words and token labels when the words are further tokenized by Tokenizer.tokenize_ner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dictionary that maps labels to numerical values**  \n",
    "Note there is an argument called `trailing_piece_tag`. BERT uses a WordPiece tokenizer which breaks down some words into multiple tokens, e.g. \"criticize\" is tokenized into \"critic\" and \"##ize\". Since the input data only come with one token label for \"criticize\", within Tokenizer.prerocess_ner_tokens, the original token label is assigned to the first token \"critic\" and the second token \"##ize\" is labeled as \"X\". By default, `trailing_piece_tag` is set to \"X\". If \"X\" already exists in your data, you can set `trailing_piece_tag` to another value that doesn't exist in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_map = create_label_map(label_list, trailing_piece_tag=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-protein',\n",
       " 'I-protein',\n",
       " 'B-DNA',\n",
       " 'I-DNA',\n",
       " 'B-cell_type',\n",
       " 'I-cell_type',\n",
       " 'B-cell_line',\n",
       " 'I-cell_line',\n",
       " 'B-RNA',\n",
       " 'I-RNA']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-protein': 1,\n",
       " 'I-protein': 2,\n",
       " 'B-DNA': 3,\n",
       " 'I-DNA': 4,\n",
       " 'B-cell_type': 5,\n",
       " 'I-cell_type': 6,\n",
       " 'B-cell_line': 7,\n",
       " 'I-cell_line': 8,\n",
       " 'B-RNA': 9,\n",
       " 'I-RNA': 10,\n",
       " 'X': 11}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(language=LANGUAGE, \n",
    "                      to_lower=DO_LOWER_CASE, \n",
    "                      cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize and preprocess text**  \n",
    "The `tokenize_ner` method of the `Tokenizer` class converts text and labels in strings to numerical features, involving the following steps:\n",
    "1. WordPiece tokenization.\n",
    "2. Convert tokens and labels to numerical values, i.e. token ids and label ids.\n",
    "3. Sequence padding or truncation according to the `max_seq_length` configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_token_ids, train_input_mask, train_trailing_token_mask, train_label_ids = \\\n",
    "    tokenizer.tokenize_ner(text=train_df[TEXT_COL],\n",
    "                           label_map=label_map,\n",
    "                           max_len=MAX_SEQ_LENGTH,\n",
    "                           labels=train_df[LABELS_COL],\n",
    "                           trailing_piece_tag=\"X\")\n",
    "test_token_ids, test_input_mask, test_trailing_token_mask, test_label_ids = \\\n",
    "    tokenizer.tokenize_ner(text=test_df[TEXT_COL],\n",
    "                           label_map=label_map,\n",
    "                           max_len=MAX_SEQ_LENGTH,\n",
    "                           labels=test_df[LABELS_COL],\n",
    "                           trailing_piece_tag=\"X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tokenizer.tokenize_ner` outputs three or four lists of numerical features lists, each sublist contains features of an input sentence: \n",
    "1. token ids: list of numerical values each corresponds to a token.\n",
    "2. attention mask: list of 1s and 0s, 1 for input tokens and 0 for padded tokens, so that padded tokens are not attended to. \n",
    "3. trailing word piece mask: boolean list, `True` for the first word piece of each original word, `False` for the trailing word pieces, e.g. ##ize. This mask is useful for removing predictions on trailing word pieces, so that each original word in the input text has a unique predicted label. \n",
    "4. label ids: list of numerical values each corresponds to an entity label, if `labels` is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample token ids:\n",
      "[15393, 118, 123, 2069, 9236, 1127, 7140, 1118, 4235, 172, 25669, 6758, 6013, 117, 1105, 147, 27843, 120, 1457, 9971, 1118, 15059, 1202, 2007, 3457, 1233, 28117, 9654, 2193, 185, 23415, 7409, 19944, 11787, 2007, 27426, 24266, 7880, 12238, 1548, 113, 19416, 1708, 118, 8544, 16523, 114, 1105, 2102, 171, 7841, 119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample attention mask:\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample trailing token mask:\n",
      "[True, False, False, False, True, True, True, True, True, True, False, False, False, True, True, True, False, False, False, False, True, True, True, False, False, False, True, False, False, True, False, False, False, False, False, True, True, False, False, False, True, True, False, False, False, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "\n",
      "Sample label ids:\n",
      "[0, 11, 11, 11, 0, 0, 0, 0, 0, 0, 11, 11, 11, 0, 0, 1, 11, 11, 11, 11, 0, 0, 0, 11, 11, 11, 0, 11, 11, 0, 11, 11, 11, 11, 11, 0, 0, 11, 11, 11, 0, 0, 11, 11, 11, 11, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample token ids:\\n{}\\n\".format(train_token_ids[0]))\n",
    "print(\"Sample attention mask:\\n{}\\n\".format(train_input_mask[0]))\n",
    "print(\"Sample trailing token mask:\\n{}\\n\".format(train_trailing_token_mask[0]))\n",
    "print(\"Sample label ids:\\n{}\\n\".format(train_label_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Token Classifier\n",
    "The value of the `language` argument determines which BERT model is used:\n",
    "* Language.ENGLISH: \"bert-base-uncased\"\n",
    "* Language.ENGLISHCASED: \"bert-base-cased\"\n",
    "* Language.ENGLISHLARGE: \"bert-large-uncased\"\n",
    "* Language.ENGLISHLARGECASED: \"bert-large-cased\"\n",
    "* Language.CHINESE: \"bert-base-chinese\"\n",
    "* Language.MULTILINGUAL: \"bert-base-multilingual-cased\"\n",
    "* Language.ENGLISHLARGEWWM: \"bert-large-uncased-whole-word-masking\"\n",
    "* Language.ENGLISHLARGECASEDWWM: \"bert-large-cased-whole-word-masking\"\n",
    "\n",
    "Here we use the base, cased pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_classifier = BERTTokenClassifier(language=LANGUAGE,\n",
    "                                       num_labels=len(label_map),\n",
    "                                       cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_EPOCHS = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/232 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1%|▏         | 3/232 [00:30<39:07, 10.25s/it]\u001b[A\n",
      "Iteration:   1%|▏         | 3/232 [00:49<39:07, 10.25s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 7/232 [01:09<37:42, 10.05s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 7/232 [01:20<37:42, 10.05s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 10/232 [01:39<37:12, 10.06s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 10/232 [01:50<37:12, 10.06s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 14/232 [02:18<36:10,  9.96s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 14/232 [02:30<36:10,  9.96s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 18/232 [02:57<35:25,  9.93s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 18/232 [03:10<35:25,  9.93s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 22/232 [03:36<34:35,  9.88s/it]\u001b[A\n",
      "Iteration:   9%|▉         | 22/232 [03:50<34:35,  9.88s/it]\u001b[A\n",
      "Iteration:  11%|█         | 26/232 [04:15<33:48,  9.85s/it]\u001b[A\n",
      "Iteration:  11%|█         | 26/232 [04:30<33:48,  9.85s/it]\u001b[A\n",
      "Iteration:  12%|█▎        | 29/232 [04:45<33:29,  9.90s/it]\u001b[A\n",
      "Iteration:  12%|█▎        | 29/232 [05:00<33:29,  9.90s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 33/232 [05:25<32:45,  9.88s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 33/232 [05:40<32:45,  9.88s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 37/232 [06:04<31:57,  9.83s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 37/232 [06:20<31:57,  9.83s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:34<31:38,  9.89s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:50<31:38,  9.89s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:13<30:56,  9.88s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:30<30:56,  9.88s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [07:52<30:11,  9.84s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [08:10<30:11,  9.84s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:31<29:23,  9.80s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:50<29:23,  9.80s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:10<28:40,  9.77s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:30<28:40,  9.77s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [09:49<28:00,  9.77s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [10:00<28:00,  9.77s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:28<27:19,  9.76s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:40<27:19,  9.76s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:07<26:37,  9.74s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:20<26:37,  9.74s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [11:45<25:58,  9.74s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [12:00<25:58,  9.74s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:24<25:18,  9.74s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:40<25:18,  9.74s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:03<24:37,  9.72s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:20<24:37,  9.72s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [13:42<23:59,  9.73s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [14:00<23:59,  9.73s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:21<23:20,  9.73s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:40<23:20,  9.73s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [15:00<22:41,  9.72s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [15:20<22:41,  9.72s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [15:39<22:03,  9.73s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [15:50<22:03,  9.73s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:18<21:24,  9.73s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:30<21:24,  9.73s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [16:57<20:45,  9.73s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [17:10<20:45,  9.73s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:36<20:07,  9.74s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:50<20:07,  9.74s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:15<19:28,  9.74s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:30<19:28,  9.74s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [18:54<18:50,  9.75s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [19:10<18:50,  9.75s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:33<18:11,  9.74s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:50<18:11,  9.74s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:12<17:32,  9.75s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:30<17:32,  9.75s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [20:51<16:52,  9.74s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [21:10<16:52,  9.74s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:29<16:12,  9.72s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:40<16:12,  9.72s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:08<15:34,  9.73s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:20<15:34,  9.73s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [22:47<14:55,  9.73s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [23:00<14:55,  9.73s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:26<14:16,  9.73s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:40<14:16,  9.73s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:05<13:37,  9.73s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:20<13:37,  9.73s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [24:44<12:58,  9.73s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [25:00<12:58,  9.73s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:23<12:20,  9.74s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:40<12:20,  9.74s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:02<11:40,  9.73s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:20<11:40,  9.73s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [26:41<11:00,  9.72s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [27:00<11:00,  9.72s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:20<10:25,  9.77s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:40<10:25,  9.77s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [27:59<09:45,  9.76s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [28:10<09:45,  9.76s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 176/232 [28:38<09:04,  9.72s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 176/232 [28:50<09:04,  9.72s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 180/232 [29:17<08:25,  9.71s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 180/232 [29:30<08:25,  9.71s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 184/232 [29:55<07:46,  9.72s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 184/232 [30:10<07:46,  9.72s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 188/232 [30:34<07:07,  9.73s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 188/232 [30:50<07:07,  9.73s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 192/232 [31:13<06:29,  9.73s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 192/232 [31:30<06:29,  9.73s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 196/232 [31:52<05:50,  9.74s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 196/232 [32:10<05:50,  9.74s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 200/232 [32:31<05:11,  9.74s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 200/232 [32:50<05:11,  9.74s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 204/232 [33:10<04:32,  9.74s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 204/232 [33:30<04:32,  9.74s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 208/232 [33:49<03:53,  9.75s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 208/232 [34:00<03:53,  9.75s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 212/232 [34:29<03:15,  9.76s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 212/232 [34:40<03:15,  9.76s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 216/232 [35:08<02:36,  9.77s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 216/232 [35:20<02:36,  9.77s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 220/232 [35:47<01:57,  9.80s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 220/232 [36:00<01:57,  9.80s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 224/232 [36:26<01:18,  9.80s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 224/232 [36:40<01:18,  9.80s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 228/232 [37:06<00:39,  9.81s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 228/232 [37:20<00:39,  9.81s/it]\u001b[A\n",
      "Epoch:  14%|█▍        | 1/7 [37:44<3:46:27, 2264.55s/it]/it]\u001b[A\n",
      "Iteration:   0%|          | 0/232 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.18479028641214146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|▏         | 4/232 [00:39<37:06,  9.77s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 4/232 [00:55<37:06,  9.77s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:17<36:25,  9.76s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:35<36:25,  9.76s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [01:57<35:49,  9.77s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [02:15<35:49,  9.77s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:36<35:13,  9.79s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:55<35:13,  9.79s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:15<34:33,  9.78s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:25<34:33,  9.78s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [03:54<33:53,  9.78s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [04:05<33:53,  9.78s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:33<33:13,  9.77s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:45<33:13,  9.77s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:12<32:33,  9.77s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:25<32:33,  9.77s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [05:51<31:57,  9.78s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [06:05<31:57,  9.78s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:31<31:20,  9.80s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:45<31:20,  9.80s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:10<30:40,  9.79s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:25<30:40,  9.79s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [07:49<30:01,  9.79s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [08:05<30:01,  9.79s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:28<29:24,  9.80s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:45<29:24,  9.80s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:07<28:43,  9.79s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:25<28:43,  9.79s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [09:47<28:04,  9.80s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [10:05<28:04,  9.80s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:26<27:23,  9.78s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:45<27:23,  9.78s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:05<26:43,  9.78s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:15<26:43,  9.78s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [11:44<26:05,  9.78s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [11:55<26:05,  9.78s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:23<25:25,  9.78s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:35<25:25,  9.78s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:02<24:45,  9.77s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:15<24:45,  9.77s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [13:41<24:08,  9.79s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [13:55<24:08,  9.79s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:21<23:29,  9.79s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:35<23:29,  9.79s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [15:00<22:51,  9.79s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [15:15<22:51,  9.79s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [15:39<22:11,  9.79s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [15:55<22:11,  9.79s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:18<21:30,  9.78s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:35<21:30,  9.78s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [16:57<20:52,  9.78s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [17:15<20:52,  9.78s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:36<20:12,  9.78s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:55<20:12,  9.78s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:15<19:32,  9.77s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:25<19:32,  9.77s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [18:54<18:52,  9.76s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [19:05<18:52,  9.76s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:33<18:16,  9.79s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:46<18:16,  9.79s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:13<17:38,  9.80s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:26<17:38,  9.80s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [20:52<17:00,  9.81s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [21:06<17:00,  9.81s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:31<16:19,  9.80s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:46<16:19,  9.80s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:10<15:40,  9.80s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:26<15:40,  9.80s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [22:49<14:59,  9.78s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [23:06<14:59,  9.78s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:28<14:20,  9.77s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:46<14:20,  9.77s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:08<13:41,  9.78s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:26<13:41,  9.78s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [24:47<13:02,  9.78s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [25:06<13:02,  9.78s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:26<12:22,  9.77s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:46<12:22,  9.77s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:05<11:43,  9.77s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:16<11:43,  9.77s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [26:44<11:04,  9.77s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [26:56<11:04,  9.77s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:23<10:25,  9.77s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:36<10:25,  9.77s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [28:02<09:46,  9.78s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [28:16<09:46,  9.78s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 175/232 [28:34<09:30, 10.01s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 175/232 [28:46<09:30, 10.01s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 179/232 [29:13<08:47,  9.96s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 179/232 [29:26<08:47,  9.96s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 183/232 [29:53<08:06,  9.93s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 183/232 [30:06<08:06,  9.93s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 187/232 [30:32<07:25,  9.89s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 187/232 [30:46<07:25,  9.89s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 191/232 [31:11<06:44,  9.87s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 191/232 [31:26<06:44,  9.87s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 195/232 [31:50<06:04,  9.85s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 195/232 [32:06<06:04,  9.85s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 199/232 [32:29<05:24,  9.84s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 199/232 [32:46<05:24,  9.84s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 203/232 [33:09<04:45,  9.83s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 203/232 [33:26<04:45,  9.83s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 206/232 [33:39<04:18,  9.94s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 206/232 [33:56<04:18,  9.94s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 210/232 [34:19<03:38,  9.91s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 210/232 [34:36<03:38,  9.91s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 214/232 [34:58<02:58,  9.90s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 214/232 [35:16<02:58,  9.90s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 218/232 [35:37<02:18,  9.87s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 218/232 [35:56<02:18,  9.87s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 222/232 [36:17<01:38,  9.86s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 222/232 [36:36<01:38,  9.86s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 226/232 [36:56<00:59,  9.86s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 226/232 [37:16<00:59,  9.86s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 230/232 [37:35<00:19,  9.85s/it]\u001b[A\n",
      "Iteration:  99%|█████████▉| 230/232 [37:46<00:19,  9.85s/it]\u001b[A\n",
      "Epoch:  29%|██▊       | 2/7 [1:15:39<3:08:58, 2267.61s/it]t]\u001b[A\n",
      "Iteration:   0%|          | 0/232 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.07510603961117308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|▏         | 4/232 [00:39<37:17,  9.82s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 4/232 [00:51<37:17,  9.82s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:18<36:34,  9.80s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:31<36:34,  9.80s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [01:57<35:58,  9.81s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [02:11<35:58,  9.81s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:37<35:20,  9.82s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:51<35:20,  9.82s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:16<34:40,  9.81s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:31<34:40,  9.81s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [03:55<34:02,  9.82s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [04:11<34:02,  9.82s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:34<33:22,  9.81s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:51<33:22,  9.81s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:14<32:43,  9.82s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:31<32:43,  9.82s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [05:53<32:06,  9.83s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [06:11<32:06,  9.83s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:32<31:26,  9.82s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:51<31:26,  9.82s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:11<30:44,  9.81s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:31<30:44,  9.81s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [07:51<30:06,  9.82s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [08:01<30:06,  9.82s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:30<29:27,  9.82s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:41<29:27,  9.82s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:09<28:47,  9.81s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:21<28:47,  9.81s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [09:48<28:08,  9.82s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [10:01<28:08,  9.82s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:28<27:30,  9.83s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:41<27:30,  9.83s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:07<26:52,  9.83s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:21<26:52,  9.83s/it]\u001b[A\n",
      "Iteration:  31%|███       | 71/232 [11:37<26:32,  9.89s/it]\u001b[A\n",
      "Iteration:  31%|███       | 71/232 [11:51<26:32,  9.89s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 75/232 [12:17<25:51,  9.88s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 75/232 [12:31<25:51,  9.88s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 79/232 [12:56<25:09,  9.87s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 79/232 [13:11<25:09,  9.87s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 83/232 [13:36<24:29,  9.87s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 83/232 [13:51<24:29,  9.87s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 87/232 [14:15<23:50,  9.86s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 87/232 [14:31<23:50,  9.86s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 91/232 [14:54<23:08,  9.85s/it]\u001b[A\n",
      "Iteration:  39%|███▉      | 91/232 [15:11<23:08,  9.85s/it]\u001b[A\n",
      "Iteration:  41%|████      | 95/232 [15:33<22:26,  9.83s/it]\u001b[A\n",
      "Iteration:  41%|████      | 95/232 [15:51<22:26,  9.83s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 99/232 [16:13<21:46,  9.82s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 99/232 [16:31<21:46,  9.82s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 103/232 [16:52<21:06,  9.82s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 103/232 [17:11<21:06,  9.82s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 107/232 [17:31<20:26,  9.81s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 107/232 [17:41<20:26,  9.81s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 111/232 [18:10<19:48,  9.82s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 111/232 [18:21<19:48,  9.82s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 115/232 [18:50<19:09,  9.83s/it]\u001b[A\n",
      "Iteration:  50%|████▉     | 115/232 [19:01<19:09,  9.83s/it]\u001b[A\n",
      "Iteration:  51%|█████▏    | 119/232 [19:29<18:29,  9.82s/it]\u001b[A\n",
      "Iteration:  51%|█████▏    | 119/232 [19:41<18:29,  9.82s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 123/232 [20:08<17:50,  9.82s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 123/232 [20:21<17:50,  9.82s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 127/232 [20:47<17:10,  9.81s/it]\u001b[A\n",
      "Iteration:  55%|█████▍    | 127/232 [21:01<17:10,  9.81s/it]\u001b[A\n",
      "Iteration:  56%|█████▋    | 131/232 [21:27<16:31,  9.82s/it]\u001b[A\n",
      "Iteration:  56%|█████▋    | 131/232 [21:41<16:31,  9.82s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 135/232 [22:06<15:51,  9.81s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 135/232 [22:21<15:51,  9.81s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 139/232 [22:45<15:12,  9.81s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 139/232 [23:01<15:12,  9.81s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 143/232 [23:24<14:32,  9.80s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 143/232 [23:41<14:32,  9.80s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 147/232 [24:04<13:53,  9.81s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 147/232 [24:21<13:53,  9.81s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 151/232 [24:43<13:14,  9.81s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 151/232 [25:01<13:14,  9.81s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 155/232 [25:22<12:35,  9.81s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 155/232 [25:41<12:35,  9.81s/it]\u001b[A\n",
      "Iteration:  69%|██████▊   | 159/232 [26:01<11:55,  9.80s/it]\u001b[A\n",
      "Iteration:  69%|██████▊   | 159/232 [26:11<11:55,  9.80s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 163/232 [26:41<11:16,  9.81s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 163/232 [26:51<11:16,  9.81s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 167/232 [27:20<10:37,  9.81s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 167/232 [27:31<10:37,  9.81s/it]\u001b[A\n",
      "Iteration:  74%|███████▎  | 171/232 [27:59<09:58,  9.81s/it]\u001b[A\n",
      "Iteration:  74%|███████▎  | 171/232 [28:11<09:58,  9.81s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 175/232 [28:38<09:18,  9.79s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 175/232 [28:51<09:18,  9.79s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 179/232 [29:17<08:39,  9.80s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 179/232 [29:31<08:39,  9.80s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 183/232 [29:57<08:00,  9.81s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 183/232 [30:11<08:00,  9.81s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 187/232 [30:36<07:20,  9.80s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 187/232 [30:51<07:20,  9.80s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 191/232 [31:15<06:41,  9.80s/it]\u001b[A\n",
      "Iteration:  82%|████████▏ | 191/232 [31:31<06:41,  9.80s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 195/232 [31:54<06:02,  9.81s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 195/232 [32:11<06:02,  9.81s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 199/232 [32:33<05:23,  9.80s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 199/232 [32:51<05:23,  9.80s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 203/232 [33:13<04:44,  9.81s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 203/232 [33:31<04:44,  9.81s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 207/232 [33:52<04:05,  9.81s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 207/232 [34:11<04:05,  9.81s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 211/232 [34:31<03:25,  9.81s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 211/232 [34:41<03:25,  9.81s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 215/232 [35:10<02:46,  9.80s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 215/232 [35:21<02:46,  9.80s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 219/232 [35:50<02:07,  9.81s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 219/232 [36:01<02:07,  9.81s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 223/232 [36:29<01:28,  9.81s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 223/232 [36:41<01:28,  9.81s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 227/232 [37:08<00:49,  9.81s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 227/232 [37:21<00:49,  9.81s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 231/232 [37:47<00:09,  9.81s/it]\u001b[A\n",
      "Epoch:  43%|████▎     | 3/7 [1:53:35<2:31:21, 2270.31s/it]t]\u001b[A\n",
      "Iteration:   0%|          | 0/232 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0439340058384977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|▏         | 4/232 [00:39<37:11,  9.79s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 4/232 [00:55<37:11,  9.79s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:18<36:31,  9.78s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:35<36:31,  9.78s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [01:57<35:53,  9.79s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [02:15<35:53,  9.79s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:36<35:14,  9.79s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:55<35:14,  9.79s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:16<34:42,  9.82s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:35<34:42,  9.82s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [03:55<34:03,  9.82s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [04:15<34:03,  9.82s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:34<33:20,  9.80s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:45<33:20,  9.80s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:13<32:40,  9.80s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:25<32:40,  9.80s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [05:52<32:01,  9.80s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [06:05<32:01,  9.80s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:32<31:22,  9.80s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:45<31:22,  9.80s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:11<30:42,  9.80s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:25<30:42,  9.80s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [07:50<30:04,  9.81s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [08:05<30:04,  9.81s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:29<29:26,  9.81s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:45<29:26,  9.81s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:09<28:49,  9.83s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:25<28:49,  9.83s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [09:48<28:09,  9.83s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [10:05<28:09,  9.83s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:27<27:29,  9.82s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:45<27:29,  9.82s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:07<26:50,  9.82s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:25<26:50,  9.82s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [11:46<26:11,  9.82s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [12:05<26:11,  9.82s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:25<25:33,  9.83s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:45<25:33,  9.83s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:05<24:52,  9.82s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:15<24:52,  9.82s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [13:44<24:14,  9.83s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [13:55<24:14,  9.83s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:23<23:35,  9.83s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:35<23:35,  9.83s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [15:02<22:54,  9.82s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [15:15<22:54,  9.82s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [15:42<22:16,  9.82s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [15:55<22:16,  9.82s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:21<21:36,  9.82s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:35<21:36,  9.82s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [17:00<20:56,  9.82s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [17:15<20:56,  9.82s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:40<20:17,  9.82s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:55<20:17,  9.82s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:19<19:36,  9.81s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:35<19:36,  9.81s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [18:58<18:56,  9.80s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [19:15<18:56,  9.80s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:37<18:15,  9.78s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:55<18:15,  9.78s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:16<17:37,  9.79s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:35<17:37,  9.79s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [20:55<16:58,  9.80s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [21:15<16:58,  9.80s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:35<16:20,  9.81s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:45<16:20,  9.81s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:14<15:42,  9.82s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:25<15:42,  9.82s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [22:53<15:03,  9.82s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [23:05<15:03,  9.82s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:33<14:24,  9.82s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:45<14:24,  9.82s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:12<13:44,  9.82s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:25<13:44,  9.82s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [24:51<13:04,  9.81s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [25:05<13:04,  9.81s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:30<12:24,  9.80s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:45<12:24,  9.80s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:09<11:45,  9.80s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:25<11:45,  9.80s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [26:48<11:06,  9.79s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [27:05<11:06,  9.79s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:28<10:26,  9.79s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:45<10:26,  9.79s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [28:07<09:47,  9.80s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [28:25<09:47,  9.80s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 176/232 [28:46<09:08,  9.80s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 176/232 [29:05<09:08,  9.80s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 180/232 [29:25<08:29,  9.80s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 180/232 [29:45<08:29,  9.80s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 184/232 [30:04<07:50,  9.79s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 184/232 [30:15<07:50,  9.79s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 188/232 [30:43<07:10,  9.79s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 188/232 [30:55<07:10,  9.79s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 192/232 [31:23<06:31,  9.80s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 192/232 [31:35<06:31,  9.80s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 196/232 [32:02<05:52,  9.80s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 196/232 [32:15<05:52,  9.80s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 200/232 [32:41<05:13,  9.80s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 200/232 [32:55<05:13,  9.80s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 204/232 [33:20<04:34,  9.80s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 204/232 [33:35<04:34,  9.80s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 207/232 [33:50<04:06,  9.86s/it]\u001b[A\n",
      "Iteration:  89%|████████▉ | 207/232 [34:05<04:06,  9.86s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 211/232 [34:30<03:26,  9.85s/it]\u001b[A\n",
      "Iteration:  91%|█████████ | 211/232 [34:45<03:26,  9.85s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 215/232 [35:09<02:47,  9.83s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 215/232 [35:25<02:47,  9.83s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 219/232 [35:48<02:07,  9.82s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 219/232 [36:05<02:07,  9.82s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 223/232 [36:27<01:28,  9.81s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 223/232 [36:45<01:28,  9.81s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 227/232 [37:06<00:49,  9.80s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 227/232 [37:25<00:49,  9.80s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 231/232 [37:46<00:09,  9.82s/it]\u001b[A\n",
      "Epoch:  57%|█████▋    | 4/7 [2:31:30<1:53:35, 2271.71s/it]t]\u001b[A\n",
      "Iteration:   0%|          | 0/232 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02909880417904913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|▏         | 4/232 [00:39<37:25,  9.85s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 4/232 [00:50<37:25,  9.85s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:18<36:38,  9.82s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:30<36:38,  9.82s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [01:57<35:58,  9.81s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [02:10<35:58,  9.81s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:36<35:20,  9.82s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:50<35:20,  9.82s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:15<34:38,  9.80s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:30<34:38,  9.80s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [03:55<34:00,  9.81s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [04:10<34:00,  9.81s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:34<33:21,  9.81s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:50<33:21,  9.81s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:13<32:39,  9.80s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:30<32:39,  9.80s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [05:52<31:59,  9.80s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [06:10<31:59,  9.80s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:31<31:21,  9.80s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:50<31:21,  9.80s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:11<30:46,  9.82s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:30<30:46,  9.82s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [07:50<30:05,  9.81s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [08:00<30:05,  9.81s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:30<29:28,  9.83s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:40<29:28,  9.83s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:09<28:47,  9.82s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:20<28:47,  9.82s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [09:48<28:08,  9.82s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [10:00<28:08,  9.82s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:27<27:32,  9.83s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:40<27:32,  9.83s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:07<26:52,  9.84s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:20<26:52,  9.84s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [11:46<26:13,  9.83s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [12:00<26:13,  9.83s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:25<25:33,  9.83s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:40<25:33,  9.83s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:05<24:52,  9.82s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:20<24:52,  9.82s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [13:44<24:11,  9.81s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [14:00<24:11,  9.81s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:23<23:31,  9.80s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:40<23:31,  9.80s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [15:02<22:51,  9.80s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [15:20<22:51,  9.80s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [15:41<22:12,  9.80s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [16:00<22:12,  9.80s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:21<21:34,  9.80s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:40<21:34,  9.80s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [17:00<20:55,  9.81s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [17:10<20:55,  9.81s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:39<20:16,  9.81s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:50<20:16,  9.81s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:18<19:36,  9.81s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:30<19:36,  9.81s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [18:57<18:57,  9.80s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [19:10<18:57,  9.80s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:37<18:18,  9.80s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:50<18:18,  9.80s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:16<17:39,  9.81s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:30<17:39,  9.81s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [20:55<17:00,  9.81s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [21:10<17:00,  9.81s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:34<16:20,  9.80s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:50<16:20,  9.80s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:14<15:41,  9.81s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:30<15:41,  9.81s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [22:53<15:02,  9.81s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [23:10<15:02,  9.81s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:32<14:23,  9.81s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:50<14:23,  9.81s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:11<13:44,  9.82s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:30<13:44,  9.82s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [24:51<13:04,  9.81s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [25:10<13:04,  9.81s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:30<12:25,  9.81s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:40<12:25,  9.81s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:10<11:49,  9.85s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:20<11:49,  9.85s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [26:49<11:09,  9.85s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [27:00<11:09,  9.85s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:28<10:29,  9.84s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:40<10:29,  9.84s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [28:08<09:52,  9.87s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [28:20<09:52,  9.87s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 175/232 [28:41<09:42, 10.22s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 175/232 [29:00<09:42, 10.22s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 178/232 [29:13<09:15, 10.29s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 178/232 [29:30<09:15, 10.29s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 182/232 [29:52<08:28, 10.17s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 182/232 [30:10<08:28, 10.17s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 185/232 [30:24<08:02, 10.26s/it]\u001b[A\n",
      "Iteration:  80%|███████▉  | 185/232 [30:40<08:02, 10.26s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 188/232 [30:54<07:29, 10.22s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 188/232 [31:10<07:29, 10.22s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 192/232 [31:33<06:43, 10.09s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 192/232 [31:51<06:43, 10.09s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 196/232 [32:12<05:59, 10.00s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 196/232 [32:31<05:59, 10.00s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 200/232 [32:52<05:18,  9.95s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 200/232 [33:11<05:18,  9.95s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 204/232 [33:31<04:37,  9.92s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 204/232 [33:51<04:37,  9.92s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 208/232 [34:10<03:57,  9.89s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 208/232 [34:21<03:57,  9.89s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 212/232 [34:49<03:17,  9.86s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 212/232 [35:01<03:17,  9.86s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 216/232 [35:29<02:37,  9.85s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 216/232 [35:41<02:37,  9.85s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 219/232 [35:59<02:09,  9.97s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 219/232 [36:11<02:09,  9.97s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 223/232 [36:38<01:29,  9.91s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 223/232 [36:51<01:29,  9.91s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 227/232 [37:18<00:49,  9.87s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 227/232 [37:31<00:49,  9.87s/it]\u001b[A\n",
      "Iteration: 100%|█████████▉| 231/232 [37:57<00:09,  9.84s/it]\u001b[A\n",
      "Epoch:  71%|███████▏  | 5/7 [3:09:36<1:15:51, 2275.98s/it]t]\u001b[A\n",
      "Iteration:   0%|          | 0/232 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.019611931382879165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|▏         | 4/232 [00:39<37:19,  9.82s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 4/232 [00:55<37:19,  9.82s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:18<36:39,  9.82s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:35<36:39,  9.82s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [01:57<35:57,  9.81s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [02:15<35:57,  9.81s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:36<35:19,  9.81s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:55<35:19,  9.81s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:15<34:35,  9.79s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:35<34:35,  9.79s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [03:55<33:55,  9.79s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [04:05<33:55,  9.79s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:33<33:13,  9.77s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:45<33:13,  9.77s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:13<32:35,  9.78s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:25<32:35,  9.78s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [05:52<31:56,  9.78s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [06:05<31:56,  9.78s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:31<31:19,  9.79s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:45<31:19,  9.79s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:10<30:37,  9.78s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:25<30:37,  9.78s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [07:49<29:59,  9.78s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [08:05<29:59,  9.78s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:28<29:20,  9.78s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:45<29:20,  9.78s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:07<28:40,  9.78s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:25<28:40,  9.78s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [09:46<28:02,  9.78s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [10:05<28:02,  9.78s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:25<27:21,  9.77s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:45<27:21,  9.77s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:05<26:41,  9.77s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:15<26:41,  9.77s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [11:44<26:05,  9.78s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [11:55<26:05,  9.78s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:23<25:27,  9.79s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:35<25:27,  9.79s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:02<24:47,  9.79s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:15<24:47,  9.79s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [13:41<24:06,  9.77s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [13:55<24:06,  9.77s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:20<23:28,  9.78s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:35<23:28,  9.78s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [14:59<22:49,  9.79s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [15:15<22:49,  9.79s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [15:39<22:10,  9.78s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [15:55<22:10,  9.78s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:18<21:32,  9.79s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:35<21:32,  9.79s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [16:57<20:52,  9.78s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [17:15<20:52,  9.78s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:36<20:13,  9.79s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:55<20:13,  9.79s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:16<19:39,  9.83s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:35<19:39,  9.83s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [18:55<18:58,  9.82s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [19:15<18:58,  9.82s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:34<18:17,  9.80s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:45<18:17,  9.80s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:13<17:39,  9.81s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:25<17:39,  9.81s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [20:52<16:59,  9.80s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [21:05<16:59,  9.80s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:32<16:21,  9.82s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:45<16:21,  9.82s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:11<15:42,  9.81s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:25<15:42,  9.81s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [22:50<15:02,  9.81s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [23:05<15:02,  9.81s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:29<14:22,  9.80s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:45<14:22,  9.80s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:09<13:43,  9.81s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:25<13:43,  9.81s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [24:48<13:02,  9.79s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [25:05<13:02,  9.79s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:27<12:23,  9.79s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:45<12:23,  9.79s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:06<11:44,  9.79s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:25<11:44,  9.79s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [26:45<11:06,  9.80s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [27:05<11:06,  9.80s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:24<10:26,  9.80s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:35<10:26,  9.80s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [28:04<09:48,  9.81s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [28:15<09:48,  9.81s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 176/232 [28:43<09:08,  9.80s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 176/232 [28:55<09:08,  9.80s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 180/232 [29:22<08:29,  9.80s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 180/232 [29:35<08:29,  9.80s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 184/232 [30:01<07:50,  9.80s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 184/232 [30:15<07:50,  9.80s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 188/232 [30:40<07:10,  9.79s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 188/232 [30:55<07:10,  9.79s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 192/232 [31:19<06:31,  9.79s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 192/232 [31:35<06:31,  9.79s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 196/232 [31:59<05:52,  9.79s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 196/232 [32:15<05:52,  9.79s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 200/232 [32:38<05:13,  9.80s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 200/232 [32:55<05:13,  9.80s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 204/232 [33:17<04:34,  9.79s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 204/232 [33:35<04:34,  9.79s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 208/232 [33:56<03:54,  9.79s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 208/232 [34:15<03:54,  9.79s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 212/232 [34:35<03:15,  9.80s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 212/232 [34:55<03:15,  9.80s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 216/232 [35:15<02:36,  9.80s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 216/232 [35:25<02:36,  9.80s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 220/232 [35:54<01:57,  9.79s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 220/232 [36:05<01:57,  9.79s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 224/232 [36:33<01:18,  9.78s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 224/232 [36:45<01:18,  9.78s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 228/232 [37:12<00:39,  9.78s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 228/232 [37:25<00:39,  9.78s/it]\u001b[A\n",
      "Epoch:  86%|████████▌ | 6/7 [3:47:27<37:54, 2274.39s/it]  t]\u001b[A\n",
      "Iteration:   0%|          | 0/232 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.014614704747459498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|▏         | 4/232 [00:39<37:17,  9.81s/it]\u001b[A\n",
      "Iteration:   2%|▏         | 4/232 [00:54<37:17,  9.81s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:18<36:38,  9.82s/it]\u001b[A\n",
      "Iteration:   3%|▎         | 8/232 [01:34<36:38,  9.82s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [01:57<36:00,  9.82s/it]\u001b[A\n",
      "Iteration:   5%|▌         | 12/232 [02:14<36:00,  9.82s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:37<35:21,  9.82s/it]\u001b[A\n",
      "Iteration:   7%|▋         | 16/232 [02:54<35:21,  9.82s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:16<34:39,  9.81s/it]\u001b[A\n",
      "Iteration:   9%|▊         | 20/232 [03:34<34:39,  9.81s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [03:55<33:59,  9.80s/it]\u001b[A\n",
      "Iteration:  10%|█         | 24/232 [04:14<33:59,  9.80s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:34<33:20,  9.81s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 28/232 [04:44<33:20,  9.81s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:13<32:41,  9.81s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 32/232 [05:24<32:41,  9.81s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [05:53<32:01,  9.80s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 36/232 [06:04<32:01,  9.80s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:32<31:22,  9.80s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 40/232 [06:44<31:22,  9.80s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:11<30:41,  9.80s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 44/232 [07:24<30:41,  9.80s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [07:50<30:01,  9.79s/it]\u001b[A\n",
      "Iteration:  21%|██        | 48/232 [08:04<30:01,  9.79s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:29<29:22,  9.79s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 52/232 [08:44<29:22,  9.79s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:08<28:43,  9.79s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 56/232 [09:24<28:43,  9.79s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [09:48<28:05,  9.80s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 60/232 [10:04<28:05,  9.80s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:27<27:31,  9.83s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 64/232 [10:44<27:31,  9.83s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:06<26:50,  9.82s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 68/232 [11:24<26:50,  9.82s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [11:46<26:08,  9.80s/it]\u001b[A\n",
      "Iteration:  31%|███       | 72/232 [12:05<26:08,  9.80s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:25<25:29,  9.81s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 76/232 [12:45<25:29,  9.81s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:04<24:49,  9.80s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 80/232 [13:15<24:49,  9.80s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [13:43<24:10,  9.80s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 84/232 [13:55<24:10,  9.80s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:22<23:32,  9.81s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 88/232 [14:35<23:32,  9.81s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [15:02<22:54,  9.81s/it]\u001b[A\n",
      "Iteration:  40%|███▉      | 92/232 [15:15<22:54,  9.81s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [15:41<22:14,  9.81s/it]\u001b[A\n",
      "Iteration:  41%|████▏     | 96/232 [15:55<22:14,  9.81s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:20<21:35,  9.81s/it]\u001b[A\n",
      "Iteration:  43%|████▎     | 100/232 [16:35<21:35,  9.81s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [16:59<20:54,  9.80s/it]\u001b[A\n",
      "Iteration:  45%|████▍     | 104/232 [17:15<20:54,  9.80s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:39<20:15,  9.80s/it]\u001b[A\n",
      "Iteration:  47%|████▋     | 108/232 [17:55<20:15,  9.80s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:18<19:35,  9.80s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 112/232 [18:35<19:35,  9.80s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [18:57<18:55,  9.79s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 116/232 [19:15<18:55,  9.79s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:36<18:16,  9.79s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 120/232 [19:55<18:16,  9.79s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:15<17:38,  9.80s/it]\u001b[A\n",
      "Iteration:  53%|█████▎    | 124/232 [20:35<17:38,  9.80s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [20:54<16:57,  9.79s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 128/232 [21:05<16:57,  9.79s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:34<16:19,  9.79s/it]\u001b[A\n",
      "Iteration:  57%|█████▋    | 132/232 [21:45<16:19,  9.79s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:13<15:39,  9.79s/it]\u001b[A\n",
      "Iteration:  59%|█████▊    | 136/232 [22:25<15:39,  9.79s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [22:52<14:59,  9.78s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 140/232 [23:05<14:59,  9.78s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:31<14:21,  9.79s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 144/232 [23:45<14:21,  9.79s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:10<13:42,  9.80s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 148/232 [24:25<13:42,  9.80s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [24:49<13:03,  9.80s/it]\u001b[A\n",
      "Iteration:  66%|██████▌   | 152/232 [25:05<13:03,  9.80s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:29<12:24,  9.80s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 156/232 [25:45<12:24,  9.80s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:08<11:45,  9.79s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 160/232 [26:25<11:45,  9.79s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [26:47<11:05,  9.79s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 164/232 [27:05<11:05,  9.79s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:26<10:26,  9.79s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 168/232 [27:45<10:26,  9.79s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [28:05<09:47,  9.79s/it]\u001b[A\n",
      "Iteration:  74%|███████▍  | 172/232 [28:25<09:47,  9.79s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 176/232 [28:45<09:09,  9.80s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 176/232 [28:55<09:09,  9.80s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 180/232 [29:24<08:29,  9.80s/it]\u001b[A\n",
      "Iteration:  78%|███████▊  | 180/232 [29:35<08:29,  9.80s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 184/232 [30:03<07:51,  9.81s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 184/232 [30:15<07:51,  9.81s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 188/232 [30:42<07:11,  9.80s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 188/232 [30:55<07:11,  9.80s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 192/232 [31:21<06:31,  9.78s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 192/232 [31:35<06:31,  9.78s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 196/232 [32:00<05:52,  9.78s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 196/232 [32:15<05:52,  9.78s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 200/232 [32:39<05:13,  9.78s/it]\u001b[A\n",
      "Iteration:  86%|████████▌ | 200/232 [32:55<05:13,  9.78s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 204/232 [33:18<04:33,  9.77s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 204/232 [33:35<04:33,  9.77s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 208/232 [33:58<03:54,  9.79s/it]\u001b[A\n",
      "Iteration:  90%|████████▉ | 208/232 [34:15<03:54,  9.79s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 212/232 [34:37<03:16,  9.80s/it]\u001b[A\n",
      "Iteration:  91%|█████████▏| 212/232 [34:55<03:16,  9.80s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 216/232 [35:16<02:36,  9.81s/it]\u001b[A\n",
      "Iteration:  93%|█████████▎| 216/232 [35:35<02:36,  9.81s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 220/232 [35:55<01:57,  9.80s/it]\u001b[A\n",
      "Iteration:  95%|█████████▍| 220/232 [36:15<01:57,  9.80s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 224/232 [36:35<01:18,  9.80s/it]\u001b[A\n",
      "Iteration:  97%|█████████▋| 224/232 [36:45<01:18,  9.80s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 228/232 [37:14<00:39,  9.81s/it]\u001b[A\n",
      "Iteration:  98%|█████████▊| 228/232 [37:25<00:39,  9.81s/it]\u001b[A\n",
      "Epoch: 100%|██████████| 7/7 [4:25:20<00:00, 2273.85s/it]/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010886221540015962\n",
      "Training time : 4.422 hrs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    token_classifier.fit(token_ids=train_token_ids, \n",
    "                         input_mask=train_input_mask, \n",
    "                         labels=train_label_ids,\n",
    "                             num_epochs=NUM_TRAIN_EPOCHS, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         learning_rate=LEARNING_RATE)\n",
    "print(\"Training time : {:.3f} hrs\".format(t.interval / 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkl_Filename = \"temp/genia_bert.pkl\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uncomment this line to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# with open(Pkl_Filename, 'wb') as file:  \n",
    "#     pickle.dump(token_classifier, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(Pkl_Filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(['B-DNA', 'I-DNA', 'O', 'O', 'B-protein', 'I-protein', 'O', 'O', 'B-protein', 'O', 'O', 'O', 'O', 'O', 'B-protein', 'O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code to test on a single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_token_ids, test_input_mask, test_trailing_token_mask, test_label_ids = \\\n",
    "    tokenizer.tokenize_ner(text=[['IL-2', 'gene', 'expression', 'and', 'NF-kappa', 'B', 'activation', 'through', 'CD28', 'requires', 'reactive', 'oxygen', 'production', 'by', '5-lipoxygenase', '.']],\n",
    "                           label_map=label_map,\n",
    "#                            max_len=16,\n",
    "                           labels=[['B-DNA', 'I-DNA', 'O', 'O', 'B-protein', 'I-protein', 'O', 'O', 'B-protein', 'O', 'O', 'O', 'O', 'O', 'B-protein', 'O']],\n",
    "                           trailing_piece_tag=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-protein': 1,\n",
       " 'I-protein': 2,\n",
       " 'B-DNA': 3,\n",
       " 'I-DNA': 4,\n",
       " 'B-cell_type': 5,\n",
       " 'I-cell_type': 6,\n",
       " 'B-cell_line': 7,\n",
       " 'I-cell_line': 8,\n",
       " 'B-RNA': 9,\n",
       " 'I-RNA': 10,\n",
       " 'X': 11}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15393,\n",
       "  118,\n",
       "  123,\n",
       "  5565,\n",
       "  2838,\n",
       "  1105,\n",
       "  151,\n",
       "  2271,\n",
       "  118,\n",
       "  24181,\n",
       "  13059,\n",
       "  139,\n",
       "  14915,\n",
       "  1194,\n",
       "  2891,\n",
       "  24606,\n",
       "  5315,\n",
       "  26844,\n",
       "  7621,\n",
       "  1707,\n",
       "  1118,\n",
       "  126,\n",
       "  118,\n",
       "  4764,\n",
       "  10649,\n",
       "  1183,\n",
       "  4915,\n",
       "  6530,\n",
       "  119,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_trailing_token_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3,\n",
       "  11,\n",
       "  11,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  11,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 0.009510550647974014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ids = loaded_model.predict(token_ids=test_token_ids, \n",
    "                                              input_mask=test_input_mask, \n",
    "                                              labels=test_label_ids, \n",
    "                                              batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3,\n",
       "  11,\n",
       "  11,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  11,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_text = dict()\n",
    "for key, value in label_map.items():\n",
    "    label_to_text[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-DNA',\n",
       " 'X',\n",
       " 'X',\n",
       " 'I-DNA',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-protein',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'I-protein',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-protein',\n",
       " 'X']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[label_to_text[x] for x in ids[0][:16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 49/49 [02:11<00:00,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 0.2593512408891503\n",
      "Prediction time : 0.036 hrs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    pred_label_ids = loaded_model.predict(token_ids=test_token_ids, \n",
    "                                              input_mask=test_input_mask, \n",
    "                                              labels=test_label_ids, \n",
    "                                              batch_size=BATCH_SIZE)\n",
    "print(\"Prediction time : {:.3f} hrs\".format(t.interval / 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "The `predict` method of the token classifier outputs label ids for all tokens, including the padded tokens. `postprocess_token_labels` is a helper function that removes the predictions on padded tokens. If a `label_map` is provided, it maps the numerical label ids back to original token labels which are usually string type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "cell_line       0.33      0.59      0.43        96\n",
      "        X       0.96      0.96      0.96      2268\n",
      "  protein       0.59      0.76      0.66       765\n",
      "      DNA       0.50      0.70      0.58       242\n",
      "cell_type       0.72      0.37      0.49       324\n",
      "      RNA       0.53      0.33      0.41        24\n",
      "\n",
      "micro avg       0.79      0.84      0.81      3719\n",
      "macro avg       0.82      0.84      0.82      3719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_tags_no_padding = postprocess_token_labels(pred_label_ids, \n",
    "                                                test_input_mask, \n",
    "                                                label_map)\n",
    "true_tags_no_padding = postprocess_token_labels(test_label_ids, \n",
    "                                                test_input_mask, \n",
    "                                                label_map)\n",
    "report_no_padding = classification_report(true_tags_no_padding, \n",
    "                                          pred_tags_no_padding, \n",
    "                                          digits=2)\n",
    "print(report_no_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "cell_line       0.34      0.64      0.44        96\n",
      "        X       0.97      0.97      0.97      2268\n",
      "  protein       0.71      0.75      0.73       765\n",
      "      DNA       0.58      0.76      0.66       242\n",
      "cell_type       0.74      0.53      0.62       324\n",
      "      RNA       0.60      0.75      0.67        24\n",
      "\n",
      "micro avg       0.84      0.86      0.85      3719\n",
      "macro avg       0.85      0.86      0.85      3719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_tags_no_padding = postprocess_token_labels(pred_label_ids, \n",
    "                                                test_input_mask, \n",
    "                                                label_map)\n",
    "true_tags_no_padding = postprocess_token_labels(test_label_ids, \n",
    "                                                test_input_mask, \n",
    "                                                label_map)\n",
    "report_no_padding = classification_report(true_tags_no_padding, \n",
    "                                          pred_tags_no_padding, \n",
    "                                          digits=2)\n",
    "print(report_no_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "cell_line       0.39      0.78      0.52       102\n",
      "cell_type       0.71      0.62      0.66       393\n",
      "      DNA       0.59      0.81      0.68       213\n",
      "        X       0.98      0.97      0.98      2250\n",
      "  protein       0.64      0.81      0.72       654\n",
      "      RNA       0.77      1.00      0.87        17\n",
      "\n",
      "micro avg       0.82      0.89      0.86      3629\n",
      "macro avg       0.85      0.89      0.87      3629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_tags_no_padding = postprocess_token_labels(pred_label_ids, \n",
    "                                                test_input_mask, \n",
    "                                                label_map)\n",
    "true_tags_no_padding = postprocess_token_labels(test_label_ids, \n",
    "                                                test_input_mask, \n",
    "                                                label_map)\n",
    "report_no_padding = classification_report(true_tags_no_padding, \n",
    "                                          pred_tags_no_padding, \n",
    "                                          digits=2)\n",
    "print(report_no_padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`postprocess_token_labels` also provides an option to remove the predictions on trailing word pieces, e.g. ##ize, so that the final predicted labels correspond to the original words in the input text. The `trailing_token_mask` is obtained from `tokenizer.tokenize_ner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "  protein       1.00      1.00      1.00         2\n",
      "      DNA       1.00      1.00      1.00         1\n",
      "\n",
      "micro avg       1.00      1.00      1.00         3\n",
      "macro avg       1.00      1.00      1.00         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_tags_no_padding_no_trailing = postprocess_token_labels(pred_label_ids, \n",
    "                                                            test_input_mask, \n",
    "                                                            label_map, \n",
    "                                                            remove_trailing_word_pieces=True, \n",
    "                                                            trailing_token_mask=test_trailing_token_mask)\n",
    "true_tags_no_padding_no_trailing = postprocess_token_labels(test_label_ids, \n",
    "                                                            test_input_mask, \n",
    "                                                            label_map, \n",
    "                                                            remove_trailing_word_pieces=True, \n",
    "                                                            trailing_token_mask=test_trailing_token_mask)\n",
    "report_no_padding_no_trailing = classification_report(true_tags_no_padding_no_trailing, \n",
    "                                                      pred_tags_no_padding_no_trailing, \n",
    "                                                      digits=2)\n",
    "print(report_no_padding_no_trailing)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
